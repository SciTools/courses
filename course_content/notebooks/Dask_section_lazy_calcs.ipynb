{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lazy calculations and efficient evaluation with Dask\n",
    "\n",
    "Summary :\n",
    "  * Iris cubes use Dask to provide \"lazy\" data arrays for delayed work and efficient out-of-core processing\n",
    "  * Many cube operations are 'lazy-preserving', producing lazy results from lazy input\n",
    "  * Where Iris does not have a suitable function, \"custom\" deferred calculations can be made with Dask, and then put into Iris cubes\n",
    "  * Multiple calculations on the same data can be computed in parallel for increased performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import iris\n",
    "print iris.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First fetch some test data\n",
    "and adjust it to look like (fake) U and V windspeeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U cube : \n",
      "northward_sea_ice_velocity / (m s-1) (time: 120; latitude: 215; longitude: 360)\n",
      "     Dimension coordinates:\n",
      "          time                            x              -               -\n",
      "          latitude                        -              x               -\n",
      "          longitude                       -              -               x\n",
      "     Auxiliary coordinates:\n",
      "          forecast_period                 x              -               -\n",
      "     Scalar coordinates:\n",
      "          forecast_reference_time: 1859-09-01 00:00:00\n",
      "\n",
      "V cube : \n",
      "eastward_sea_ice_velocity / (m s-1) (time: 120; latitude: 215; longitude: 360)\n"
     ]
    }
   ],
   "source": [
    "from iris import sample_data_path\n",
    "import glob\n",
    "\n",
    "filepaths = glob.glob(sample_data_path('UM', '*.pp'))\n",
    "filepath = filepaths[0]\n",
    "u_cube = iris.load_cube(filepaths)\n",
    "\n",
    "u_cube.coord('time').bounds = None\n",
    "u_cube.attributes.clear()\n",
    "u_cube.cell_methods = None\n",
    "\n",
    "v_cube = u_cube.copy()\n",
    "v_cube.coord('time').points = u_cube.coord('time').points\n",
    "v_cube.rename('eastward_sea_ice_velocity')\n",
    "\n",
    "print 'U cube : \\n', u_cube\n",
    "print\n",
    "print 'V cube : \\n', v_cube.summary(shorten=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in lazy operations.\n",
    "\n",
    "Let's calculate windspeeds.\n",
    "\n",
    "Vector magnitude can be made from the U and V cubes using the Iris built-in \"cube arithmetic\" operators.  \n",
    "(i.e. + - * / etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind_speed / (m.s-1)                (time: 120; latitude: 215; longitude: 360)\n",
      "     Dimension coordinates:\n",
      "          time                           x              -               -\n",
      "          latitude                       -              x               -\n",
      "          longitude                      -              -               x\n",
      "     Auxiliary coordinates:\n",
      "          forecast_period                x              -               -\n",
      "     Scalar coordinates:\n",
      "          forecast_reference_time: 1859-09-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "cube_windspeed = (u_cube* u_cube + v_cube * v_cube) ** 0.5\n",
    "cube_windspeed.rename('wind_speed')\n",
    "print cube_windspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This result is itself a lazy cube \n",
    "\n",
    "Iris cube arithmetic operators are lazy-preserving   \n",
    "(i.e. results will be lazy if the inputs are)\n",
    "\n",
    "Thus, the actual data has not yet been fetched, and the result values are not yet calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cube_windspeed.has_lazy_data() =  True\n"
     ]
    }
   ],
   "source": [
    "print 'cube_windspeed.has_lazy_data() = ', cube_windspeed.has_lazy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data realisation\n",
    "\n",
    "When actual values are required, data will be fetched from disk + the calculations made.  \n",
    "The result is then stored in the cube as 'real' data (i.e. a numpy array), known as **realisation**.\n",
    "\n",
    "This can be shown working with a ***copy*** of the above cube (to avoid realising the original)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE windspeed_copy.has_lazy_data() =  True\n",
      " some data : \n",
      "[[ 0.02622383  0.05331731  0.05291287]\n",
      " [ 0.01845959  0.05698491  0.04619173]]\n",
      "AFTER windspeed_copy.has_lazy_data() =  False\n"
     ]
    }
   ],
   "source": [
    "windspeed_copy = cube_windspeed.copy()\n",
    "print 'BEFORE windspeed_copy.has_lazy_data() = ', windspeed_copy.has_lazy_data()\n",
    "print ' some data : \\n', windspeed_copy.data[10, 20:22, 300:303]\n",
    "print 'AFTER windspeed_copy.has_lazy_data() = ', windspeed_copy.has_lazy_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching data has 'realised' this cube.\n",
    "However the original windspeed cube, and the U and V it is based on are all unaffected.  \n",
    "This means that when results are fetched from those cubes, all the data will have to be loaded again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cube       windspeed_copy,                             \"wind_speed\" : data lazy = False\n",
      "cube       cube_windspeed,                             \"wind_speed\" : data lazy = True\n",
      "cube               u_cube,             \"northward_sea_ice_velocity\" : data lazy = True\n",
      "cube               v_cube,              \"eastward_sea_ice_velocity\" : data lazy = True\n"
     ]
    }
   ],
   "source": [
    "def cubevar_datastates(*varnames):\n",
    "    for varname in varnames:\n",
    "        cube = globals()[varname]\n",
    "        print 'cube {}, {} : data lazy = {}'.format(varname.rjust(20),\n",
    "                                               ('\"' + cube.name() + '\"').rjust(40),\n",
    "                                               cube.has_lazy_data())\n",
    "\n",
    "cubevar_datastates('windspeed_copy', 'cube_windspeed', 'u_cube', 'v_cube')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits\n",
    "The point of this is especially clear when the data is very large, e.g. too big to fit in memory.  \n",
    "In that case, the results of calculations cannot possibly be computed as a complete array in memory.\n",
    "\n",
    "Instead, however :\n",
    "  * selected smaller regions can be extracted and realised for use, e.g. to make a plot\n",
    "    * (which can obviously be repeated to cover a dataset in sections)\n",
    "  * statistical summaries can be calculated, which are usually much smaller than the full data + can be worked with directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-defined lazy calculations\n",
    "\n",
    "Now let's calculate wind directions (angles).\n",
    "\n",
    "There is no cube arctan function in Iris, but we can use Dask instead.  \n",
    "We construct the result just as if we were using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array as da\n",
    "\n",
    "# Calculate arctan(u, v)\n",
    "lazy_winddirs = da.arctan2(u_cube.lazy_data(), v_cube.lazy_data())\n",
    "# Convert to degrees\n",
    "lazy_winddirs = da.rad2deg(lazy_winddirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put these angles into a cube.\n",
    "We copy the windspeed cube as it will have the right shape and other metadata.  \n",
    "Then just put the lazy data inside, and fix up the name and units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wind_direction / (m.s-1)            (time: 120; latitude: 215; longitude: 360)\n",
      "     Dimension coordinates:\n",
      "          time                           x              -               -\n",
      "          latitude                       -              x               -\n",
      "          longitude                      -              -               x\n",
      "     Auxiliary coordinates:\n",
      "          forecast_period                x              -               -\n",
      "     Scalar coordinates:\n",
      "          forecast_reference_time: 1859-09-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Make a cube suitable to hold windspeed angles.\n",
    "cube_winddir = cube_windspeed.copy()\n",
    "cube_winddir.rename('wind_direction')\n",
    "cube_winddir.unit = 'degrees'\n",
    "\n",
    "# Insert lazy values as cube data.\n",
    "cube_winddir.data = lazy_winddirs\n",
    "\n",
    "print cube_winddir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "We now make some statistics based on the calculated windspeed and direction, using the Iris MEAN and STD_DEV operations.\n",
    "\n",
    "Note that these statistical operations are lazy-preserving.\n",
    "\n",
    "( But, not ***all*** Iris statistics are lazy-preserving ...  \n",
    "MIN and MAX have yet to be made lazy, and various other operations may require 'real' data.  \n",
    "In such cases, *applying the statistic will load all the data*.  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample cube = mean windspeed:\n",
      "wind_speed / (m.s-1)                (time: 120)\n",
      "     Dimension coordinates:\n",
      "          time                           x\n",
      "     Auxiliary coordinates:\n",
      "          forecast_period                x\n",
      "     Scalar coordinates:\n",
      "          forecast_reference_time: 1859-09-01 00:00:00\n",
      "          latitude: 3.8147e-06 degrees, bound=(-90.0, 90.0) degrees\n",
      "          longitude: 180.5 degrees, bound=(0.5, 360.5) degrees\n",
      "     Cell methods:\n",
      "          mean: latitude, longitude\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/h05/itpp/git/iris/iris_main/lib/iris/cube.py:3158: UserWarning: Collapsing spatial coordinate 'latitude' without weighting\n",
      "  warnings.warn(msg.format(coord.name()))\n",
      "/home/h05/itpp/git/iris/iris_main/lib/iris/coords.py:1209: UserWarning: Collapsing a non-contiguous coordinate. Metadata may not be fully descriptive for 'longitude'.\n",
      "  warnings.warn(msg.format(self.name()))\n"
     ]
    }
   ],
   "source": [
    "cube_mean_windspeed = cube_windspeed.collapsed(('latitude', 'longitude'), iris.analysis.MEAN)\n",
    "cube_stdev_windspeed = cube_windspeed.collapsed(('latitude', 'longitude'), iris.analysis.STD_DEV)\n",
    "cube_mean_ang = cube_winddir.collapsed(('latitude', 'longitude'), iris.analysis.MEAN)\n",
    "cube_stdev_ang = cube_winddir.collapsed(('latitude', 'longitude'), iris.analysis.STD_DEV)\n",
    "print 'Sample cube = mean windspeed:\\n', cube_mean_windspeed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check : these are all lazy results\n",
    "-- no data has yet been loaded, or any actual calculations done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cube  cube_mean_windspeed,                             \"wind_speed\" : data lazy = True\n",
      "cube cube_stdev_windspeed,                             \"wind_speed\" : data lazy = True\n",
      "cube        cube_mean_ang,                         \"wind_direction\" : data lazy = True\n",
      "cube       cube_stdev_ang,                         \"wind_direction\" : data lazy = True\n"
     ]
    }
   ],
   "source": [
    "cubevar_datastates('cube_mean_windspeed', 'cube_stdev_windspeed', 'cube_mean_ang', 'cube_stdev_ang')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that realising *any* of these cubes takes a little time\n",
    "\n",
    "...As this reads all the data from disk.  \n",
    "for example ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_mean_ang_cube = cube_mean_ang.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some data :  -4.52267\n",
      "1 loop, best of 1: 412 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "print 'Some data : ', temp_mean_ang_cube.data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result :\n",
    "Although this operation had to scan all the data, only the statistical result is saved.\n",
    "\n",
    "It makes sense that the source data is not stored, it could be larger than memory.  \n",
    "However, it means that data is re-scanned from disk when any of the statistics are calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time the calculation of each statistic :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetch                     wind_speed = 0.47\n",
      "Fetch                     wind_speed = 0.54\n",
      "Fetch                 wind_direction = 0.45\n",
      "Fetch                 wind_direction = 0.47\n",
      "Total individual fetch+calculate times        = 1.93\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "def timeop(op):\n",
    "    t0 = datetime.datetime.now()\n",
    "    op()\n",
    "    t1 = datetime.datetime.now()\n",
    "    return (t1 - t0).total_seconds()\n",
    "\n",
    "stats_cubes = [cube_mean_windspeed, cube_stdev_windspeed, cube_mean_ang, cube_stdev_ang]\n",
    "assert all([cube.has_lazy_data() for cube in stats_cubes])\n",
    "time_total = 0.0\n",
    "for cube in stats_cubes:\n",
    "    time = timeop(lambda: cube.copy().data)\n",
    "    print 'Fetch {} = {:0.2f}'.format(cube.name().rjust(30), time)\n",
    "    time_total += time\n",
    "\n",
    "print 'Total individual fetch+calculate times        = {:0.2f}'.format(time_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimise the calculation of multiple results\n",
    "By telling Dask to calculate these results at the same time, this problem can be avoided :  \n",
    "Multiple statistics can be calculated in a single pass through the data.\n",
    "\n",
    "For this, we pass the cube lazy data elements to dask in a single operation.\n",
    "\n",
    "### Time the combined calculation + compare with separate operation timings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined fetch+calculate time = 1.24\n",
      "  --> speedup ~36%\n"
     ]
    }
   ],
   "source": [
    "time_combined = timeop(lambda: da.compute(*[cube.lazy_data() for cube in stats_cubes]))\n",
    "percent_speedup = 100.0*(1.0 - time_combined / time_total)\n",
    "print 'Combined fetch+calculate time = {:0.2f}'.format(time_combined)\n",
    "print '  --> speedup ~{:02.0f}%'.format(percent_speedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
